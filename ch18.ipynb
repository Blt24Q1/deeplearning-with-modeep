{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moFVlmfsMeEY"
   },
   "source": [
    "# 18장 시퀀스 배열로 다루는 순환 신경망(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"https://raw.githubusercontent.com/taehojo/taehojo.github.io/master/assets/images/linktocolab.png\" align=\"left\"/> ](https://colab.research.google.com/github/taehojo/deeplearning/blob/master/colab/ch18-colab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BV80bxS7MeEd"
   },
   "source": [
    "## 1. LSTM을 이용한 로이터 뉴스 카테고리 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LedMrcmrMeEe",
    "outputId": "a42c4a8c-c37d-4731-836e-1edb5f8b60cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 카테고리\n",
      "8982 학습용 뉴스 기사\n",
      "2246 테스트용 뉴스 기사\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 2, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.datasets import reuters       # 로이터 뉴스 데이터셋 불러오기\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터를 불러와 학습셋, 테스트셋으로 나눕니다.\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=1000, test_split=0.2)\n",
    "\n",
    "# 데이터를 확인해 보겠습니다.\n",
    "category = np.max(y_train) + 1\n",
    "print(category, '카테고리')\n",
    "print(len(X_train), '학습용 뉴스 기사')\n",
    "print(len(X_test), '테스트용 뉴스 기사')\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6Ka1uHnMeEg",
    "outputId": "a182a8c5-58bf-448e-abae-5bfc86b09f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "450/450 [==============================] - 10s 17ms/step - loss: 2.1655 - accuracy: 0.4490 - val_loss: 1.8017 - val_accuracy: 0.5120\n",
      "Epoch 2/200\n",
      "450/450 [==============================] - 7s 16ms/step - loss: 1.7172 - accuracy: 0.5625 - val_loss: 1.7238 - val_accuracy: 0.5512\n",
      "Epoch 3/200\n",
      "450/450 [==============================] - 7s 15ms/step - loss: 1.6017 - accuracy: 0.5925 - val_loss: 1.5836 - val_accuracy: 0.5997\n",
      "Epoch 4/200\n",
      "450/450 [==============================] - 7s 15ms/step - loss: 1.4182 - accuracy: 0.6372 - val_loss: 1.3914 - val_accuracy: 0.6532\n",
      "Epoch 5/200\n",
      "450/450 [==============================] - 8s 19ms/step - loss: 1.2339 - accuracy: 0.6854 - val_loss: 1.2934 - val_accuracy: 0.6710\n",
      "Epoch 6/200\n",
      "450/450 [==============================] - 7s 16ms/step - loss: 1.1052 - accuracy: 0.7200 - val_loss: 1.2135 - val_accuracy: 0.6790\n",
      "Epoch 7/200\n",
      "450/450 [==============================] - 8s 18ms/step - loss: 1.0119 - accuracy: 0.7408 - val_loss: 1.1839 - val_accuracy: 0.7039\n",
      "Epoch 8/200\n",
      "450/450 [==============================] - 8s 18ms/step - loss: 0.9395 - accuracy: 0.7578 - val_loss: 1.1755 - val_accuracy: 0.7124\n",
      "Epoch 9/200\n",
      "450/450 [==============================] - 8s 19ms/step - loss: 0.8654 - accuracy: 0.7780 - val_loss: 1.1471 - val_accuracy: 0.7186\n",
      "Epoch 10/200\n",
      "450/450 [==============================] - 9s 19ms/step - loss: 0.7981 - accuracy: 0.7937 - val_loss: 1.1506 - val_accuracy: 0.7186\n",
      "Epoch 11/200\n",
      "450/450 [==============================] - 7s 16ms/step - loss: 0.7343 - accuracy: 0.8123 - val_loss: 1.1501 - val_accuracy: 0.7222\n",
      "Epoch 12/200\n",
      "450/450 [==============================] - 7s 16ms/step - loss: 0.6765 - accuracy: 0.8285 - val_loss: 1.1726 - val_accuracy: 0.7240\n",
      "Epoch 13/200\n",
      " 51/450 [==>...........................] - ETA: 5s - loss: 0.6492 - accuracy: 0.8422"
     ]
    }
   ],
   "source": [
    "# 단어의 수를 맞추어 줍니다. \n",
    "X_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "\n",
    "# 원-핫 인코딩 처리를 합니다.\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# 모델의 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 100))\n",
    "model.add(LSTM(100, activation='tanh'))\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# 모델의 실행 옵션을 정합니다.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 학습의 조기 중단을 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history = model.fit(X_train, y_train, batch_size=20, epochs=200, validation_data=(X_test, y_test), callbacks=[early_stopping_callback])\n",
    "\n",
    "# 테스트 정확도를 출력합니다.\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgAQgBNZMeEg",
    "outputId": "ce61c9a3-a396-4469-ddaf-7071820ba2eb"
   },
   "outputs": [],
   "source": [
    "# (X_train, y_train), (X_test, y_test) = reuters.load_data(test_split=0.2)  # 모든 내용이 나오도록 num_word 삭제\n",
    "\n",
    "# 단어 인덱스 가져오기\n",
    "word_index = reuters.get_word_index()\n",
    "\n",
    "# 인덱스 단어 맞춘 딕셔너리 생성\n",
    "index_word_dict = {index: word for word, index in word_index.items()}\n",
    "\n",
    "# 첫 번째 뉴스 기사 디코딩\n",
    "decoding = ' '.join([index_word_dict.get(i - 3, '') for i in X_train[0]])\n",
    "\n",
    "print(decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgAQgBNZMeEg",
    "outputId": "ce61c9a3-a396-4469-ddaf-7071820ba2eb"
   },
   "outputs": [],
   "source": [
    "# 학습셋과 테스트셋의 오차를 저장합니다. \n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "# 그래프로 표현해 보겠습니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시하겠습니다. \n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJe5NA-bMeEh"
   },
   "source": [
    "## 2. LSTM과 CNN의 조합을 이용한 영화 리뷰 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62aG-sujMeEi",
    "outputId": "625b8b9b-e9d8-462b-8177-662687479e8d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터를 불러와 학습셋, 테스트셋으로 나눕니다.\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000)\n",
    "\n",
    "# 단어의 수를 맞추어 줍니다. \n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "\n",
    "# 모델의 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(64, 5, padding='valid', activation='relu',strides=1))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(55))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSEtxKjqMeEi",
    "outputId": "1f5e7dea-2538-4030-db2f-fe98a0602315"
   },
   "outputs": [],
   "source": [
    "# 모델의 실행 옵션을 정합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 학습의 조기 중단을 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history = model.fit(X_train, y_train, batch_size=40, epochs=100, validation_split=0.25, callbacks=[early_stopping_callback])\n",
    "\n",
    "# 테스트 정확도를 출력합니다.\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPI4hRamMeEj",
    "outputId": "89226bfa-55ec-4eb0-f9f8-f3dd9a943b66"
   },
   "outputs": [],
   "source": [
    "# 학습셋과 테스트셋의 오차를 저장합니다. \n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "# 그래프로 표현해 보겠습니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시하겠습니다. \n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fh7X-05sMeEk"
   },
   "source": [
    "## 3. 어텐션을 사용한 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKVqBc7PMeEk",
    "outputId": "e5f3c810-dd55-4325-95b5-72f58716386c"
   },
   "outputs": [],
   "source": [
    "!pip install attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxyCnbT0MeEl",
    "outputId": "65cbe0a4-430d-4469-cb62-c895410b53ee"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from attention import Attention\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터를 불러와 학습셋, 테스트셋으로 나눕니다.\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000)\n",
    "\n",
    "# 단어의 수를 맞추어 줍니다. \n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "\n",
    "# 모델의 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 500))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Attention())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# 모델의 실행 옵션을 정합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 학습의 조기 중단을 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history = model.fit(X_train, y_train, batch_size=40, epochs=100,  validation_data=(X_test, y_test), callbacks=[early_stopping_callback])\n",
    "\n",
    "# 테스트 정확도를 출력합니다.\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12YPivgwMeEl",
    "outputId": "05115359-fe12-4572-eb9e-caed77eb0417"
   },
   "outputs": [],
   "source": [
    "# 학습셋과 테스트셋의 오차를 저장합니다. \n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "# 그래프로 표현해 보겠습니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시하겠습니다. \n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfPCePP4MeEl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ch18-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
